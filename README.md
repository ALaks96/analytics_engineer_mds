# ğŸš´â€â™‚ï¸ Projet : The Paris VÃ©lib' Monitor

Bienvenue. Si vous lisez ceci, c'est que vous voulez passer du cÃ´tÃ© technique de la Data ("Analytics Engineering").

Ce projet est conÃ§u comme un jeu vidÃ©o en 2 Phases :
1.  **Phase 1 (MVP) :** On fait tout "Ã  la main" pour comprendre la logique mÃ©tier (SQL, KPI, Dashboard). Objectif : Avoir un dashboard qui marche en 2 jours.
2.  **Phase 2 (Industrialisation) :** On automatise tout avec du code (Python, API, Docker) pour que Ã§a tourne tout seul. C'est le vrai travail d'ingÃ©nieur.

---

## ğŸ›  PrÃ©-requis & Outils

Avant de commencer, installez ces bases.
* **VS Code** (Votre atelier de code) : [TÃ©lÃ©charger ici](https://code.visualstudio.com/)
* **Git** (Votre sauvegarde) : [TÃ©lÃ©charger ici](https://git-scm.com/downloads)
* **Un compte Google** (Pour le Cloud).

---

# ğŸ Phase 1 : Le MVP (Minimum Viable Product)

**Objectif :** Analyser la donnÃ©e statique. On s'en fiche de l'automatisation pour l'instant, on veut voir des chiffres.

## Ã‰tape 1 : Le Cloud (BigQuery)
Vous n'allez pas stocker les donnÃ©es sur votre ordi (Excel), mais dans un "Data Warehouse" dans le Cloud. On utilise **Google BigQuery** car ils ont une "Sandbox" gratuite (pas de carte bleue requise).

### ğŸ§  Le Concept : Data Warehouse
C'est un entrepÃ´t gÃ©ant capable de traiter des milliards de lignes en secondes. Contrairement Ã  Excel, on ne "voit" pas la donnÃ©e, on lui pose des questions via du code (SQL).

### ğŸ¯ Mission
1.  CrÃ©er un projet sur Google Cloud Platform (GCP).
2.  Activer l'API BigQuery.
3.  CrÃ©er un "Dataset" (un dossier) appelÃ© `raw_velib`.
4.  TÃ©lÃ©charger ce fichier JSON sur votre ordi (clic droit > enregistrer sous) : [Data VÃ©lib Temps RÃ©el](https://velib-metropole-opendata.smoove.pro/opendata/Velib_Metropole/station_status.json)
5.  Uploader ce fichier manuellement dans le dataset `raw_velib` pour crÃ©er une table `stations`.

### ğŸ”— Liens utiles
* **Tuto Indispensable :** [Comment activer la BigQuery Sandbox (Gratuit)](https://cloud.google.com/bigquery/docs/sandbox?hl=fr)
* **Tuto :** [Charger un fichier local dans BigQuery](https://cloud.google.com/bigquery/docs/loading-data-local?hl=fr) (Regardez juste la partie "Console Cloud").

---

## Ã‰tape 2 : La Transformation (dbt & SQL)
C'est le cÅ“ur du mÃ©tier d'Analytics Engineer. Votre donnÃ©e brute est moche (JSON imbriquÃ©, types bizarres). On va utiliser **dbt** (data build tool) pour la nettoyer via du SQL.

### ğŸ§  Le Concept : dbt
Avant dbt, on Ã©crivait des scripts SQL bordÃ©liques qu'on lanÃ§ait Ã  la main. dbt permet de structurer le SQL comme du code informatique (versionnÃ©, testÃ©, documentÃ©).

### ğŸ¯ Mission
1.  Installer Python et dbt sur votre ordinateur.
2.  Connecter dbt Ã  votre BigQuery.
3.  Ã‰crire un modÃ¨le SQL pour nettoyer la table brute.

### ğŸ”— Liens utiles
* [Tuto dbt pour BigQuery (Suivez les Ã©tapes "Installation" et "Connect")](https://docs.getdbt.com/guides/bigquery?step=1)

### ğŸ†˜ Cheat Codes

<details>
<summary>ğŸ‘€ <strong>Cheat 1 : L'installation (Terminal)</strong></summary>

Ouvrez votre terminal (dans VS Code) et tapez :
```bash
# Installe dbt pour BigQuery
pip install dbt-bigquery

# Initialise le projet (rÃ©pondez aux questions)
dbt init velib_project
```
Si la commande pip n'est pas trouvÃ©e, vÃ©rifiez que vous avez cochÃ© "Add Python to PATH" lors de l'installation de Python.

</details>

<details> <summary>ğŸ‘€ <strong>Cheat 2 : La configuration (profiles.yml)</strong></summary>

C'est souvent lÃ  que Ã§a bloque. Pour vous connecter Ã  BigQuery sans prise de tÃªte au dÃ©but, utilisez la mÃ©thode OAuth (authentification via le navigateur) lors du dbt init.

</details>

<details> <summary>ğŸ‘€ <strong>Cheat 3 : Le Code SQL (Le modÃ¨le)</strong></summary>

CrÃ©ez un fichier models/staging/stg_stations.sql :

```sql
SELECT
    stationCode as station_id,
    num_bikes_available as nb_velos,
    is_renting = 'OUI' as est_ouverte,
    capacity
FROM `votre-projet-gcp.raw_velib.stations`
```
Puis lancez la commande dbt run dans le terminal.

</details>

## Ã‰tape 3 : La Dataviz
La donnÃ©e est propre. Montrez-la.

### ğŸ¯ Mission
Ouvrir Google Looker Studio.

Connecter la source de donnÃ©es "BigQuery" -> Votre table crÃ©Ã©e par dbt.

Faire un graph : "Top 10 des stations avec le plus de capacitÃ©".

# ğŸš€ Phase 2 : L'Industrialisation (Software Engineering)
Vous avez validÃ© la logique. Maintenant, on arrÃªte de charger les fichiers Ã  la main. On veut du temps rÃ©el.

## Ã‰tape 4 : Python & API
On va remplacer votre clic manuel "Uploader un fichier" par un robot.

### ğŸ§  Le Concept : API & JSON
Une API est une prise Ã©lectrique sur le web qui donne de la donnÃ©e. Le JSON est le format de cette donnÃ©e.

### ğŸ¯ Mission
CrÃ©er un script extract.py qui tÃ©lÃ©charge la donnÃ©e VÃ©lib et l'affiche.

### ğŸ†˜ Cheat Codes
<details> <summary>ğŸ‘€ <strong>Cheat : Le Script de base</strong></summary>

```python
import requests
import json

# L'URL magique
url = "https://velib-metropole-opendata.smoove.pro/opendata/Velib_Metropole/station_status.json"

# On appelle le serveur
reponse = requests.get(url)

# On lit le contenu
data = reponse.json()

# Affichez pour comprendre la structure
print(data) 
```
</details>

## Ã‰tape 5 : Docker & Airbyte (Le niveau Pro)
Vous ne lancerez pas le script Python depuis votre ordi tous les jours. On utilise un outil d'ingestion : Airbyte.

### ğŸ§  Le Concept : Conteneurs
Docker permet d'installer Airbyte sans polluer votre Mac/PC. C'est une "boÃ®te" Ã©tanche.

### ğŸ¯ Mission
Installer Docker Desktop.

Installer Airbyte en local.

Connecter l'API VÃ©lib (Source) Ã  BigQuery (Destination) dans Airbyte.

### ğŸ”— Liens utiles
Installer Docker

Deployer Airbyte Localement (Le tuto officiel)

### ğŸ†˜ Cheat Codes
<details> <summary>ğŸ‘€ <strong>Cheat : Configurer Airbyte</strong></summary>

Dans Airbyte (localhost:8000), crÃ©ez une Source "File" (Fichier).

URL : L'url du JSON VÃ©lib.

Format : JSON.

Destination : BigQuery (Il faudra crÃ©er un "Service Account" sur Google Cloud pour donner la permission Ã  Airbyte d'Ã©crire. C'est l'Ã©tape la plus dure du projet, googlez "Create Service Account BigQuery".

</details>

### ğŸ‰ Le Final Boss
Si vous avez rÃ©ussi Ã  :

Avoir Airbyte qui tourne et envoie la donnÃ©e tous les jours.

Avoir dbt qui nettoie cette donnÃ©e.

Avoir Looker Studio qui affiche la donnÃ©e Ã  jour.